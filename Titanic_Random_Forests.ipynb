{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c286740c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0bb919fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_status(df):\n",
    "    title_dict = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Dona\": \"Royalty\",\n",
    "    \"Sir\" : \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royalty\"}\n",
    "    \n",
    "    titles = []\n",
    "    for name in df['Name']:\n",
    "        title = name.split(',')[-1].split('.')[0]\n",
    "        titles.append(title[1:])\n",
    "    df['Name'] = titles\n",
    "    \n",
    "    \n",
    "    # a map of more aggregated title\n",
    "    # we map each title\n",
    "    df['Name'] = df.Name.map(title_dict)\n",
    "    df.rename(columns = {'Name':'Status'}, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1ba8e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ticket_type(df):\n",
    "    \n",
    "    ticket_type_dict = {\n",
    "        'SCA4': 'A',\n",
    "        'SCA3': 'A',\n",
    "        'A4': 'A',\n",
    "        'A': 'A',\n",
    "        'AQ3': 'A',\n",
    "        'AQ4': 'A',\n",
    "        'SP': 'A',\n",
    "        'SOP': 'A',\n",
    "        'FA': 'A',\n",
    "        'SCOW': 'A',\n",
    "        'AS': 'A',\n",
    "        'SOPP': 'A',\n",
    "        'FC': 'A',\n",
    "        'SOTONO2': 'A', \n",
    "        'CASOTON': 'A',\n",
    "        'A5': 'A',\n",
    "        'WC': 'A',\n",
    "        'SOTONOQ': 'A',\n",
    "        'STONOQ': 'A',\n",
    "        'PC': 'B',\n",
    "        'STONO2': 'B',\n",
    "        'PP': 'B',\n",
    "        'SCPARIS': 'B',\n",
    "        'CA': 'B',\n",
    "        'SOC': 'B',\n",
    "        'C': 'B',\n",
    "        'FCC': 'B',\n",
    "        'SWPP': 'B',\n",
    "        'SC': 'B',\n",
    "        'STONO': 'B',\n",
    "        'SCAH': 'B',\n",
    "        'WEP': 'B',\n",
    "        'PPP': 'B',\n",
    "        'LP': 'B',\n",
    "        'BASIC': 'C',\n",
    "    }\n",
    "\n",
    "    ticket_types = []\n",
    "    for ticket in df['Ticket']:\n",
    "        if pd.notna(ticket): \n",
    "            ticket_split = ticket.split(' ')\n",
    "            if len(ticket_split) > 1:\n",
    "                ticket_type = ticket_split[0]\n",
    "                ticket_type = ticket_type.replace('.','')\n",
    "                ticket_type = ticket_type.replace('/','')\n",
    "                ticket_type = ticket_type.upper()\n",
    "                ticket_types.append(ticket_type)\n",
    "            else: ticket_types.append('BASIC')\n",
    "        else: ticket_types.append(ticket)\n",
    "    df['TicketType'] = ticket_types\n",
    "#     df['TicketType'] = df.TicketType.map(ticket_type_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "72eaeaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_ticket_type(df):\n",
    "#     ticket_types = []\n",
    "#     for ticket in df['Ticket']:\n",
    "#         if pd.notna(ticket): \n",
    "#             ticket_split = ticket.split(' ')\n",
    "#             if len(ticket_split) > 1:\n",
    "#                 ticket_types.append(ticket_split[0])\n",
    "#             else: ticket_types.append('basic')\n",
    "#         else: ticket_types.append(ticket)\n",
    "#     df['TicketType'] = ticket_types\n",
    "# #     df.rename(columns = {'Ticket':'TicketType'}, inplace = True)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f3efbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabin_to_deck(df):\n",
    "    decks = []\n",
    "    for cabin in df['Cabin']:\n",
    "        if pd.notna(cabin): decks.append(cabin[0])\n",
    "        else: decks.append('Basic')\n",
    "    df['Cabin'] = decks\n",
    "    df.rename(columns = {'Cabin':'Deck'}, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6ad5f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ticket_number(df):\n",
    "    ticket_numbers = []\n",
    "    for ticket in df['Ticket']:\n",
    "        if ticket == 'LINE': ticket_numbers.append(0)\n",
    "        elif pd.notna(ticket):\n",
    "            ticket_split = ticket.split(' ')\n",
    "            ticket_numbers.append(int(ticket_split[-1]))\n",
    "        else: ticket_numbers.append(ticket)\n",
    "    ticket_numbers_arr = np.array(ticket_numbers) #Experiment\n",
    "    uni, count = np.unique(ticket_numbers_arr,return_counts=True)\n",
    "    aux = uni[count < 2].tolist()\n",
    "    for i, value in enumerate(ticket_numbers_arr):\n",
    "        if value in aux:\n",
    "            ticket_numbers_arr[i] = 0\n",
    "#     ticket_numbers_arr[ticket_numbers_arr < 2] = 0 #Experiment\n",
    "    df['TicketNumber'] = ticket_numbers_arr #Experiment\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "2737ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_group_size(df):\n",
    "    group_size = []\n",
    "    for i, row in df.iterrows():\n",
    "        group_size.append(len((df['TicketNumber'] == row['TicketNumber']).values.nonzero()[0]))\n",
    "    df['GroupSize'] = group_size\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "efde7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_number_of_friends(df):\n",
    "    number_of_friends = []\n",
    "    for i, row in df.iterrows():\n",
    "        number_of_friends.append(row['GroupSize'] - row['FamSize'])\n",
    "    df['NumberOfFriends'] = number_of_friends\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2eda5dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_age_estimated(df):\n",
    "    age_estimated = []\n",
    "    for i in range(len(df)):\n",
    "        if df['Age'].values[i] != df['Age'].values[i]:\n",
    "            age_estimated.append(0)\n",
    "        elif df['Age'].values[i] != int(df['Age'].values[i]) and df['Age'].values[i] > 1:\n",
    "            age_estimated.append(1)\n",
    "        else: \n",
    "            age_estimated.append(0)\n",
    "    df['AgeEstimated'] = age_estimated\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "0fa53e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fam_size(df):\n",
    "    fam_size  = []\n",
    "    for i in range(len(df)):\n",
    "        fam_size.append(df['SibSp'][i]+df['Parch'][i])\n",
    "    df['FamSize'] = fam_size\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6d345af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fare_per_person(df):\n",
    "    fare_per_person = []\n",
    "    for i in range(len(df)):\n",
    "        fare_per_person.append(df['Fare'][i]/(df['FamSize'][i]+1))\n",
    "    df['FarePerPerson'] = fare_per_person\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "4e8e8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_ages(df, train_index):\n",
    "    ages = []\n",
    "    grouped_train = df.iloc[:train_index].groupby(['Sex','Pclass','Status'])\n",
    "    grouped_median_train = grouped_train.median()\n",
    "    grouped_median_train = grouped_median_train.reset_index()[['Sex', 'Pclass', 'Status', 'Age']]\n",
    "    for i, row in df.iterrows():\n",
    "        if row['Age'] != row['Age']: \n",
    "            condition = (\n",
    "                (grouped_median_train['Sex'] == row['Sex']) & \n",
    "                (grouped_median_train['Status'] == row['Status']) & \n",
    "                (grouped_median_train['Pclass'] == row['Pclass'])\n",
    "            ) \n",
    "            ages.append(grouped_median_train[condition]['Age'].values[0])\n",
    "        else: ages.append(row['Age'])\n",
    "    df['Age'] = ages\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3a344924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_age_times_class(df):\n",
    "    age_times_class = []\n",
    "    for i in range(len(df)):\n",
    "        age_times_class.append(df['Pclass'][i]*df['Age'][i])\n",
    "    df['AgeClass'] = age_times_class\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "34dc96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_life_stage(df):\n",
    "    minor = np.zeros(len(df), 'int')\n",
    "    adult = np.zeros(len(df), 'int')\n",
    "    elderly = np.zeros(len(df), 'int')\n",
    "\n",
    "    for i, age in enumerate(df['Age'].values):\n",
    "        if age < 18:\n",
    "            minor[i] = 1\n",
    "        elif age < 60:\n",
    "            adult[i] = 1\n",
    "        else:\n",
    "            elderly[i] = 1\n",
    "\n",
    "    df['Minor'] = minor\n",
    "    df['Adult'] = adult\n",
    "    df['Elderly'] = elderly\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "bcceca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fam_size_cat(df):\n",
    "    singleton = np.zeros(len(df), 'int')\n",
    "    small_fam = np.zeros(len(df), 'int')\n",
    "    large_fam = np.zeros(len(df), 'int')\n",
    "\n",
    "    for i, fam_size in enumerate(df['FamSize'].values):\n",
    "        if fam_size == 1:\n",
    "            singleton[i] = 1\n",
    "        elif fam_size <= 4:\n",
    "            small_fam[i] = 1\n",
    "        else:\n",
    "            large_fam[i] = 1\n",
    "\n",
    "    df['Singleton'] = singleton\n",
    "    df['SmallFam'] = small_fam\n",
    "    df['LargeFam'] = large_fam\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "456a7c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorify(df, columns):\n",
    "    rectifier = 1\n",
    "    for column in columns:\n",
    "        category_dict = {}\n",
    "        unique_categories = df[column].unique()\n",
    "        unknown_index = (unique_categories != unique_categories).nonzero()[0]\n",
    "        unique_categories = unique_categories.tolist()\n",
    "\n",
    "        if len(unknown_index): \n",
    "            category_indexes = list(range(len(unique_categories)))\n",
    "            unknown = unique_categories[unknown_index[0]]\n",
    "            category_indexes[0] = unknown\n",
    "            unique_categories.pop(unknown_index[0])\n",
    "            unique_categories.insert(0,unknown)\n",
    "\n",
    "        else:\n",
    "            category_indexes = list(range(1,len(unique_categories)+1))\n",
    "\n",
    "        for i in range(len(unique_categories)):\n",
    "            category_dict[unique_categories[i]] = category_indexes[i]\n",
    "\n",
    "        new_column = []\n",
    "        for i in range(len(df)):\n",
    "            new_value = category_dict[df[column][i]]\n",
    "            if new_value == new_value: new_value = int(new_value)\n",
    "            new_column.append(new_value)\n",
    "\n",
    "        df[column] = new_column\n",
    "#         df[column] = new_column.astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "369d9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(df, ignore_columns):\n",
    "    for column in df.columns:\n",
    "        if column in ignore_columns: continue\n",
    "        elif df[column].isna().any():\n",
    "            median = df[column].describe()['50%']\n",
    "            nan_indexes = df[column].isna().values\n",
    "            new_column = np.array(df[column])\n",
    "            new_column[nan_indexes] = median\n",
    "#             new_column = new_column.astype('int')\n",
    "            df[column] = new_column\n",
    "            df[f'{column}Missing'] = nan_indexes \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a82be6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integerize(df, columns):\n",
    "    for column in columns:\n",
    "        df = df.astype({column: 'int'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "af089160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(predictions, targets):\n",
    "    return 100*(len((predictions == targets).nonzero()[0]) / len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "60e55e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "    ).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c038f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_hot_encode(df, key):\n",
    "#     for i in range(len(df[key].unique())):\n",
    "#         df[f'{key}_{i+1}'] = np.zeros(len(df), 'int')\n",
    "\n",
    "#     for i in range(len(df)):\n",
    "#         value = df[key].values[i]\n",
    "#         df[f'{key}_{value}'][i] = 1\n",
    "#     df = df.drop([key], axis=1)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f45e08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, key):\n",
    "    array_list = []\n",
    "    for i in range(len(df[key].unique())):\n",
    "#         df[f'{key}_{i+1}'] = np.zeros(len(df), 'int')\n",
    "        array_list.append(np.zeros(len(df),'int'))\n",
    "        \n",
    "    for i in range(len(df)):\n",
    "        value = df[key].values[i]\n",
    "        array_list[value-1][i] = 1\n",
    "    \n",
    "    for i in range(len(df[key].unique())):\n",
    "        df[f'{key}_{i+1}'] = array_list[i]\n",
    "        \n",
    "    df = df.drop([key], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6def5d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/francisco/workspace/titanic_kaggle/titanic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "9db16aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_df = pd.read_csv(f'{path}/train.csv',low_memory=False)\n",
    "original_test_df = pd.read_csv(f'{path}/test.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "016311f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.concat([original_train_df, original_test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "46de7893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44843/424082697.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_df['AgeMissing'][(complete_df['Age'] != complete_df['Age'])] = 1\n"
     ]
    }
   ],
   "source": [
    "complete_df = name_to_status(complete_df)\n",
    "# complete_df = add_ticket_type(complete_df)\n",
    "complete_df = add_ticket_number(complete_df)\n",
    "# complete_df = add_group_size(complete_df)\n",
    "complete_df = complete_df.drop(['Ticket'], axis=1)\n",
    "complete_df = cabin_to_deck(complete_df)\n",
    "complete_df = add_age_estimated(complete_df)\n",
    "complete_df['AgeMissing'] = np.zeros(len(complete_df),'int')\n",
    "complete_df['AgeMissing'][(complete_df['Age'] != complete_df['Age'])] = 1\n",
    "complete_df = fill_ages(complete_df,891)\n",
    "# complete_df = add_life_stage(complete_df)\n",
    "complete_df = add_fam_size(complete_df)\n",
    "# complete_df = add_number_of_friends(complete_df)\n",
    "# complete_df = add_fam_size_cat(complete_df)\n",
    "complete_df['Fare'] = complete_df['Fare'].fillna(complete_df['Fare'].median())\n",
    "complete_df = add_fare_per_person(complete_df)\n",
    "complete_df = complete_df.drop(['Fare'], axis=1)\n",
    "complete_df = add_age_times_class(complete_df)\n",
    "complete_df['Embarked'] = complete_df['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "69a40c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = complete_df\n",
    "# figure = plt.figure(figsize=(25, 7))\n",
    "# plt.hist([data[data['Survived'] == 1]['Sex'], data[data['Survived'] == 0]['Sex']], \n",
    "#          stacked=True, color = ['g','r'],\n",
    "#          bins = 50, label = ['Survived','Dead'])\n",
    "# plt.xlabel('Fare')\n",
    "# plt.ylabel('Number of passengers')\n",
    "# plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1fcf81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A -> SCA4 A4 SP SOP FA SCOW AS SOPP FC SOTONO2 CASOTON A5 WC SOTONOQ\n",
    "# B -> PC STONO2 PP SCPARIS CA SOC C FCC SWPP SC STONO SCAH WEP PPP\n",
    "# C -> BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "78ca02ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete_df['TicketType'].iloc[891:].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e79f50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = categorify(complete_df,['Status', 'Deck', 'Sex', 'Embarked', 'TicketNumber'])\n",
    "# complete_df = fill_missing(complete_df, ['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ec4d9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['Pclass', 'Status', 'Deck', 'Embarked', 'TicketNumber']:\n",
    "    complete_df = one_hot_encode(complete_df, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6d559e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = complete_df.iloc[:891]\n",
    "valid_df = complete_df.iloc[712:891].reset_index()\n",
    "test_df = complete_df.iloc[891:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e68475ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = integerize(train_df, cat)\n",
    "# valid_df = integerize(valid_df, cat)\n",
    "# test_df = integerize(test_df, cat[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ffe45599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_men_df = train_df[train_df['Sex'] == 2].drop(['Sex'], axis=1)\n",
    "# valid_men_df = valid_df[valid_df['Sex'] == 2].drop(['Sex'], axis=1)\n",
    "# train_women_df = train_df[train_df['Sex'] == 1].drop(['Sex'], axis=1)\n",
    "# valid_women_df = valid_df[valid_df['Sex'] == 1].drop(['Sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f2d828fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 10000, \n",
    "              'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}\n",
    "\n",
    "rf = ensemble.RandomForestClassifier(**parameters)\n",
    "# rf = ensemble.RandomForestClassifier(n_estimators=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "df7264ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Fit man\n",
    "# rf.fit(train_men_df.values[:,2:],train_men_df.values[:,1])\n",
    "# preds_rf = rf.predict(valid_men_df.values[:,3:])\n",
    "# metric(preds_rf.astype('int'), valid_men_df['Survived'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "617929cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Fit women\n",
    "# rf.fit(train_women_df.values[:,2:],train_women_df.values[:,1])\n",
    "# preds_rf = rf.predict(valid_women_df.values[:,3:])\n",
    "# metric(preds_rf.astype('int'), valid_women_df['Survived'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b458cc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.5027932960894"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit all data\n",
    "rf.fit(train_df.values[:,2:],train_df.values[:,1])\n",
    "preds_rf = rf.predict(valid_df.values[:,3:])\n",
    "metric(preds_rf.astype('int'), valid_df['Survived'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b6cae",
   "metadata": {},
   "source": [
    "88.8268156424581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "59bc22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7271657d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Status_1</td>\n",
       "      <td>0.193558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.188042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AgeClass</td>\n",
       "      <td>0.077365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Status_3</td>\n",
       "      <td>0.074504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Status_2</td>\n",
       "      <td>0.063069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TicketType_14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TicketType_10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TicketType_8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Deck_9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>TicketType_35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cols       imp\n",
       "14       Status_1  0.193558\n",
       "0             Sex  0.188042\n",
       "10       AgeClass  0.077365\n",
       "16       Status_3  0.074504\n",
       "15       Status_2  0.063069\n",
       "..            ...       ...\n",
       "45  TicketType_14  0.000000\n",
       "41  TicketType_10  0.000000\n",
       "39   TicketType_8  0.000000\n",
       "28         Deck_9  0.000000\n",
       "66  TicketType_35  0.000000\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_feat_importance(rf,valid_df.iloc[:,3:])\n",
    "# rf_feat_importance(rf,train_df.drop(['Survived'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28229ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_df['Sex'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "34522beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(figsize=(12, 4))\n",
    "# plot_partial_dependence(rf, valid_df.iloc[:,3:], ['Age'],\n",
    "# grid_resolution=20, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b598ae6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a1357786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_df = pd.DataFrame()\n",
    "preds_rf_test = rf.predict(test_df.values[:,3:])\n",
    "preds_rf_df = pd.DataFrame()\n",
    "\n",
    "# preds_df['PassengerId'] = test_df['PassengerId'].values\n",
    "# preds_df['Survived'] = preds_clf.astype('int')\n",
    "preds_rf_df['PassengerId'] = test_df['PassengerId'].values\n",
    "preds_rf_df['Survived'] = preds_rf_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e0887725",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf_df.to_csv(f'{path}/submission_rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33dd47",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5bafae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = rf.predict(train_df.values[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "242b53fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = train_df['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e49a588d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876543209876543"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(preds_train == gt)/len(gt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
